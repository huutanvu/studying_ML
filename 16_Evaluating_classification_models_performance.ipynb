{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"Datasets\"))\n",
    "sys.path.append(os.path.abspath(\"Images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives & Negatives\n",
    "<img src=\"Images/12_1_logistic_problem.JPG\" height=\"300\">\n",
    "- Any below 0.5 => 0, any above 0.5 => 1\n",
    "- Problem: the actual y value is not predicted correctly:\n",
    "<img src=\"Images/12_2_logistic_problem_2.JPG\" height=\"300\">\n",
    "- What actually happen is in red, predicted value is in gray.\n",
    "- So we have only #1, and #4 are predicted correctly.\n",
    "- However, the #2, #3 are predicted false. #2 should be 1, but it's predicted as 0 => **False Negative** (or Type II error), #3 should be 0, but predicted as 1 => **False Positive** (or Type I error)\n",
    "- Can be remembered: Type I error is not as dangerous as Type II error, however, it depends on the situation. i.e: thief in FBI touch sensor (False Positive will allow the thief enter)\n",
    "\n",
    "### Confusion Matrix\n",
    "- Matrix of number of true positive, false positive, true negative and false negative:\n",
    "<img src=\"Images/12_3_confusion_matrix.JPG\" height=\"300\">\n",
    "\n",
    "### Accuracy Paradox \n",
    "- *Paradox*: a statement or proposition that, despite sound (or apparently sound) reasoning from acceptable premises, leads to a conclusion that seems senseless, logically unacceptable, or self-contradictory.\n",
    "- Consider the following Confusion matrix:\n",
    "<img src=\"Images/12_4_scenario_1.JPG\" height=\"300\">\n",
    "- We see that in most of the case, the machine will predict 0, it means not take place. So basically, the records will move from right to left column:\n",
    "<img src=\"Images/12_4_scenario_2.JPG\" height=\"300\">\n",
    "- Why would we abandon a model? After abandon (decide not to use the model), the accuracy rate increases. That's why you should not base your judgement using the accuracy rate. Because it misleads you. That's why call Paradox.\n",
    "\n",
    "### CAP Curve\n",
    "- Consider the following situation: we send letters to customer to sell something, how many will response? It's a random variable, but we know it's approximate 10%\n",
    "<img src=\"Images/12_5_CAP_1.JPG\" height=\"300\">\n",
    "- Now our task is to build a model to learn about the customer who will buy our products. E.g: male/female, nationality, ... so that we can send the letters to those with similar characteristics next time.\n",
    "- So in the next sending, we will have higher response rate:\n",
    "<img src=\"Images/12_5_CAP_2.JPG\" height=\"300\">\n",
    "- The difference is the area between red and blue line. If the area is large, it means we build a good model, while it's not good if the red line is too close to the blue one.\n",
    "- Now we convert to percentages: \n",
    "<img src=\"Images/12_5_CAP_3.JPG\" height=\"300\">\n",
    "- There's another line, which is called ideal model, that you can predict exactly who will buy the product:\n",
    "<img src=\"Images/12_5_CAP_4.JPG\" height=\"300\">\n",
    "- Crystal ball: you only need to contact 10% people to get 100% purchased.\n",
    "- Note:\n",
    "    - CAP: Cumulative Accuracy Profile\n",
    "    - ROC: Receiver Operating Characteristic\n",
    "\n",
    "### CAP Curve Analysis\n",
    "- What can we derive from the CAP curve? \n",
    "- The closer to the blue line, the worse, the closer to the perfect line, the better.\n",
    "<img src=\"Images/12_6_AR.JPG\" height=\"300\">\n",
    "- It means the closer AR to one, the better ($a_p$ is the whole area between gray and blue line, not only the half). However, it's hard to visualize and calculate the area under those curves.\n",
    "=> Use Statistics\n",
    "<img src=\"Images/12_7_X.JPG\" height=\"300\">\n",
    "- If with less than 50% of people contacted, we get 90% -> 100%, it's overfitted, it means one of the independent variables is a post-facto variable, meaning it shouldn't be in the model, because it's looking into the future. For example, a person who leaves the bank will always have credit to 0, if we take the credit = 0 into consideration, it will always be true => overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
